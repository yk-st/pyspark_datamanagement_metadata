21/11/23 11:30:47 @INFO @CodeGenerator@ Code generated in 5.273542 ms
21/11/23 11:30:47 @INFO @MemoryStore@ Block broadcast_80 stored as values in memory (estimated size 194.4 KiB, free 428.9 MiB)
21/11/23 11:30:47 @INFO @MemoryStore@ Block broadcast_80_piece0 stored as bytes in memory (estimated size 34.4 KiB, free 428.8 MiB)
21/11/23 11:30:47 @INFO @BlockManagerInfo@ Added broadcast_80_piece0 in memory on 192.168.0.30:64662 (size: 34.4 KiB, free: 433.7 MiB)
21/11/23 11:30:47 @INFO @SparkContext@ Created broadcast 80 from showString at NativeMethodAccessorImpl.java:0
21/11/23 11:30:47 @INFO @FileSourceScanExec@ Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/11/23 11:30:47 @INFO @SparkContext@ Starting job: showString at NativeMethodAccessorImpl.java:0
21/11/23 11:30:47 @INFO @DAGScheduler@ Got job 54 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/11/23 11:30:47 @INFO @DAGScheduler@ Final stage: ResultStage 79 (showString at NativeMethodAccessorImpl.java:0)
21/11/23 11:30:47 @INFO @DAGScheduler@ Parents of final stage: List()
21/11/23 11:30:47 @INFO @DAGScheduler@ Missing parents: List()
21/11/23 11:30:47 @INFO @DAGScheduler@ Submitting ResultStage 79 (MapPartitionsRDD[190] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/11/23 11:30:47 @INFO @MemoryStore@ Block broadcast_81 stored as values in memory (estimated size 17.0 KiB, free 428.8 MiB)
21/11/23 11:30:47 @INFO @MemoryStore@ Block broadcast_81_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 428.8 MiB)
21/11/23 11:30:47 @INFO @BlockManagerInfo@ Added broadcast_81_piece0 in memory on 192.168.0.30:64662 (size: 6.5 KiB, free: 433.7 MiB)
21/11/23 11:30:47 @INFO @SparkContext@ Created broadcast 81 from broadcast at DAGScheduler.scala:1427
21/11/23 11:30:47 @INFO @DAGScheduler@ Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[190] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/11/23 11:30:47 @INFO @TaskSchedulerImpl@ Adding task set 79.0 with 1 tasks resource profile 0
21/11/23 11:30:47 @INFO @TaskSetManager@ Starting task 0.0 in stage 79.0 (TID 413) (192.168.0.30, executor driver, partition 0, PROCESS_LOCAL, 5004 bytes) taskResourceAssignments Map()
21/11/23 11:30:47 @INFO @Executor@ Running task 0.0 in stage 79.0 (TID 413)
21/11/23 11:30:47 @INFO @FileScanRDD@ Reading File path: file:///Users/saitouyuuki/Desktop/src/pyspark_dataprofiling_dataquality/dataset/metadata_tmp.db/sample_metadata/part-00000-ceeffe8c-4838-46bb-9eec-71d850e2c245-c000.snappy.parquet, range: 0-5134, partition values: [empty row]
21/11/23 11:30:47 @INFO @Executor@ Finished task 0.0 in stage 79.0 (TID 413). 2111 bytes result sent to driver
21/11/23 11:30:47 @INFO @TaskSetManager@ Finished task 0.0 in stage 79.0 (TID 413) in 5 ms on 192.168.0.30 (executor driver) (1/1)
21/11/23 11:30:47 @INFO @TaskSchedulerImpl@ Removed TaskSet 79.0, whose tasks have all completed, from pool 
21/11/23 11:30:47 @INFO @DAGScheduler@ ResultStage 79 (showString at NativeMethodAccessorImpl.java:0) finished in 0.009 s
21/11/23 11:30:47 @INFO @DAGScheduler@ Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
21/11/23 11:30:47 @INFO @TaskSchedulerImpl@ Killing all running tasks in stage 79: Stage finished
21/11/23 11:30:47 @INFO @DAGScheduler@ Job 54 finished: showString at NativeMethodAccessorImpl.java:0, took 0.010103 s
21/11/23 11:30:50 @INFO @SparkUI@ Stopped Spark web UI at http://192.168.0.30:4040
21/11/23 11:30:50 @INFO @MapOutputTrackerMasterEndpoint@ MapOutputTrackerMasterEndpoint stopped!
21/11/23 11:30:51 @INFO @MemoryStore@ MemoryStore cleared
21/11/23 11:30:51 @INFO @BlockManager@ BlockManager stopped
21/11/23 11:30:51 @INFO @BlockManagerMaster@ BlockManagerMaster stopped
21/11/23 11:30:51 @INFO @OutputCommitCoordinator$OutputCommitCoordinatorEndpoint@ OutputCommitCoordinator stopped!
21/11/23 11:30:51 @INFO @SparkContext@ Successfully stopped SparkContext

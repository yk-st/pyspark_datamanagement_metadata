{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本セクションの目次\n",
    "1. テクニカルメタデータについて\n",
    "2. テクニカルメタデータの一種データプロファイリング\n",
    "3. PySparkでデータプロファイリングをしてみよう1 \n",
    "4. PySparkでデータプロファイリングをしてみようその２\n",
    "5. PySparkでデータプロファイリングをしてみようその3\n",
    "6. データプロファイリングの結果をSparkテーブルに格納してみよう\n",
    "7. データ品質"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テクニカルメタデータについて\n",
    "テクニカルメタデータとは、技術的な詳細を表すものです。  \n",
    "例えば、テーブルのフォーマット(Parquet？CSVなのか？)は何か？やデータの形はどのような状態なのか？  \n",
    "\n",
    "といった情報を取得することになります。  \n",
    "\n",
    "特にデータを利用するエンジニア向けの情報になることが多いですが、次に紹介するデータプロファイリングはエンジニアだけでなくビジネスユーザにも有効な情報を提供することが可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テクニカルメタデータの一種データプロファイリング\n",
    "テクニカルメタデータの一種にはデータプロファリングがあります。  \n",
    "データプロファイリングは、データの特性をクエリせずともわかるようにすることが目的になります。\n",
    "\n",
    "特にクラウド環境では使った分だけお金を取られるため、できる限り無駄なクエリはユーザに発行させないことが重要です。\n",
    "\n",
    "ユーザ1000人がcount文を打つだけでも相当な金額になることがあるのです。\n",
    "\n",
    "ここからは、データプロファリングをどうのように取得していくのかというイメージをSparkを使いながら実行していきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コンソールで設定したSparkとNoteBookを接続します(動かす前に毎度実行する必要があります)\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pysparkに必要なライブラリを読み込む\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#spark sessionの作成\n",
    "# spark.ui.enabled trueとするとSparkのGUI画面を確認することができます\n",
    "# spark.eventLog.enabled true　とすると　GUIで実行ログを確認することができます\n",
    "# GUIなどの確認は最後のセクションで説明を行います。\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"chapter1\") \\\n",
    "    .config(\"hive.exec.dynamic.partition\", \"true\") \\\n",
    "    .config(\"hive.exec.dynamic.partition.mode\", \"nonstrict\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"JST\") \\\n",
    "    .config(\"spark.ui.enabled\",\"true\") \\\n",
    "    .config(\"spark.eventLog.enabled\",\"true\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# spark.xxxxxと記載することで処理を分散させることが可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySparkでデータプロファイリングをしてみようその１\n",
    "\n",
    "データプロファイリングその１では、以下の3つを算出してみます。  \n",
    "3つのうち件数をrow_num(件数)をメタデータストアに保存していきます。\n",
    "\n",
    "- 件数\n",
    "- 平均\n",
    "- 合計値\n",
    "\n",
    "## 件数/平均/合計の使い道\n",
    "例えば件数はよく、異常な状態を見付けることに使えます。  \n",
    "例えば、前日までに１０件だったものが急に1000件になったらアラートを鳴らすということにも使えたりします。  \n",
    "データ基盤は時には何万というテーブルが存在しているため、一つ一つ目で見るのは不可能に近いのが現実です。  \n",
    "そこで件数のような簡単なチェックを入れておくことでも、テーブル数が増え続けても問題ないデータ基盤を作ることが可能です。  \n",
    "\n",
    "一方で、取得しやすいがゆえに何も考えずに取得することは無意味になりますので、しっかりと自身の環境に適用できるかどうかを判断することは大切になります。  \n",
    "例えば、年齢の合計値はあまり意味を成さないかもしれませんし時と場合によっては、合計を知ることで何か得るものがあるかもしれません。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 件数の取得\n",
    "spark.sql(\"REFRESH TABLE data_management_crush_course.jinko_table \")\n",
    "record_num=spark.sql(\"select count(*) as row_num from data_management_crush_course.jinko_table \")\n",
    "record_num.show()\n",
    "\n",
    "# 件数情報を取得する\n",
    "record_count=record_num.collect()[0].asDict()['row_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均と合計値\n",
    "# 今回は平均として、女性と男性の合計値の平均をとっていこうと思います。\n",
    "spark.sql(\"REFRESH TABLE data_management_crush_course.jinko_table \")\n",
    "sum=spark.sql(\"select cast(sum(jinko_male)+sum(jinko_femail) as decimal(19, 0)) as sum from data_management_crush_course.jinko_table \")\n",
    "# decimalにcastしないと数値が指数表記になってみづらくなるのでdecimalにしています。\n",
    "sum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均と合計値\n",
    "# 今回は平均として、女性と男性の全体の平均をとっていこうと思います。\n",
    "spark.sql(\"REFRESH TABLE data_management_crush_course.jinko_table \")\n",
    "avg=spark.sql(\"\"\"\n",
    "select avg(sokei) as avg \n",
    " from \n",
    "   data_management_crush_course.jinko_table\n",
    "\"\"\")\n",
    "avg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySparkでデータプロファイリングをしてみようその２\n",
    "データプロファリングその２では、以下の２つを算出していきます。\n",
    "\n",
    "- カーディナリティ\n",
    "- セレクティビティ\n",
    "\n",
    "# カーディナリティの使い道\n",
    "カーディナリティとはどれだけ値がバラけているかを示す指標です。  \n",
    "ビッグデータ基盤におけるカーディナリティはスモールファイル問題やデータスキューネスを発見するための手段としてビッグデータ基盤では使われます。  \n",
    "データスキューネスとは、データに偏りがある状態を指します。  \n",
    "\n",
    "ビッグデータ基盤における偏りやスモールファイルは非常に問題になることがあります。  \n",
    "例えば、クエリのエラーを多発させたり、データの転送を遅くさせたりするする原因にもなります。  \n",
    "\n",
    "スモールファイル問題について詳しく知りたい方は是非以下のコースも受講してみてください。  \n",
    "https://www.udemy.com/course/python-spark-pyspark/?referralCode=E67BF8B61F65866794EB   \n",
    "\n",
    "# セレクティビティの使い道\n",
    "セレクティビティとは、検索した時に結果が何件返却されるか？というものです  \n",
    "\n",
    "セレクティビティは、クエリのしやすさに直結してきます。  \n",
    "データを探索する際に、重複したデータが出てきたらどうでしょうか(そもそも重複に気付けない可能性がありますが)？  \n",
    "重複を除く処理をSQLに記載しなければなりませんし、さらには  \n",
    "最終的な分析結果を間違えることもあります。たとえば、結果が2倍になってしまうかも。  \n",
    "数億というレコードの中で重複を分析の結果だけ見て判断するというのはできないものです。  \n",
    "そうなれば、再度モデルの作成仕直しや開発のやり直しをしなければならなくなります。  \n",
    "\n",
    "ビッグデータ基盤にはPK（プライマリーキー）のような仕組みを持っているものが少なく、データの重複が多々発生してしまいます。  \n",
    "\n",
    "そこでセレクティビティのチェックを行うことによって、重複しているデータを見つけ出し対処を行うことができるのです※。  \n",
    "\n",
    "※どのような対処を取るべきなのか？についてはデータ品質管理という方法があります。準備が出来次第別のコースで作成予定です。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+------------------+-------------------+---------------+-----------------+----------------------+------------------------+------------------+\n",
      "|cardinaryty_code|cardinaryty_gengo|cardinaryty_wareki|cardinaryty_seireki|cardinaryty_chu|cardinaryty_sokei|cardinaryty_jinko_male|cardinaryty_jinko_femail|cardinaryty_kenmei|\n",
      "+----------------+-----------------+------------------+-------------------+---------------+-----------------+----------------------+------------------------+------------------+\n",
      "|            0.17|             0.00|              0.02|               0.02|           0.00|             1.01|                  0.97|                    1.07|              0.16|\n",
      "+----------------+-----------------+------------------+-------------------+---------------+-----------------+----------------------+------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct\n",
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "# カーディナリティを測ってみます\n",
    "card=spark.sql(\"select * from data_management_crush_course.jinko_table\")\n",
    "\n",
    "cols_cardinality = card.select([(approx_count_distinct(c)/card.count()). \\\n",
    "    cast(DecimalType(38,2)).alias(\"cardinaryty_\"+c) for c in card.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cardinality.show() \n",
    "# approx(正確さを捨て速度と引き換えに概算値を出してくれるもの)\n",
    "# 数値が大きければ大きいほど値がバラけています(カーディナリティが高い)。\n",
    "# 数値が小さければ小さいほど値が同じで値はバラけていません(カーディナリティが低い)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT code)|\n",
      "+--------------------+\n",
      "|                  50|\n",
      "+--------------------+\n",
      "\n",
      "+-----------+------+\n",
      "|trunsaction|master|\n",
      "+-----------+------+\n",
      "|         48|    50|\n",
      "+-----------+------+\n",
      "\n",
      "+-----------+\n",
      "|selectivity|\n",
      "+-----------+\n",
      "|       0.96|\n",
      "+-----------+\n",
      "\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct\n",
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "# 今回はcodeを条件として指定した時に、どれだけ件数が返却される可能性があるかを検証してみます。\n",
    "# jinko_tableとjinko_codeテーブル(全国のコードが削除されている＆＆神奈川のコードが変更されている)\n",
    "# jinko_codeテーブルベースで検索した件数と、オリジナルの生の件数を割り算することでセレクティビティを出すことが可能です。\n",
    "\n",
    "#オリジナルの件数を表示\n",
    "spark.sql(\"select count(distinct jinko.code) from data_management_crush_course.jinko_table jinko\").show()\n",
    "\n",
    "#　セレクティビティはキーを指定した場合（今回の場合はcode）レコードの返却はどれくらいであるかを想定するものです\n",
    "card=spark.sql(\"\"\" \n",
    "select count(distinct jinko.code) trunsaction , count( distinct num.num_code) master from\n",
    "  data_management_crush_course.jinko_table jinko,\n",
    "  (select code as num_code from data_management_crush_course.jinko_table) num\n",
    "where jinko.code in (select code as num_code from data_management_crush_course.jinko_code)\n",
    "\"\"\")\n",
    "\n",
    "card.show()\n",
    "\n",
    "# 件数が一致しているならば返却されるはず\n",
    "# そうでなければ欠落が発生する\n",
    "cols_selctivity = card.select((card.trunsaction/card.master).cast(DecimalType(38,2)).alias(\"selectivity\"))\n",
    "\n",
    "cols_selctivity.show()\n",
    "# 表示された結果がおおよその返却結果（件数）になります。\n",
    "# 今回の結果だと6件ほど返されるテーブルになりそうですね\n",
    "\n",
    "\n",
    "# 今回はパーティションを指定した時を前提にどれくらいの件数が返却されるのかを\n",
    "cols_selctivity.createOrReplaceTempView(\"tmp\")\n",
    "list_selectivity=spark.sql(\"\"\"\n",
    "select \n",
    "selectivity\n",
    " as concat from tmp\n",
    "\"\"\"\n",
    ").collect()[0].asDict()['concat']\n",
    "\n",
    "#調べた結果として取得して値を格納しておきます\n",
    "print(list_selectivity)\n",
    "\n",
    "# 1の場合はレコードが必ず一件返ってくることが想定される\n",
    "# 1より大きい場合はレコードが1件以上返却される場合がある\n",
    "# 1より小さい場合はレコードが一件も返却されない場合がある\n",
    "\n",
    "# 今回は0.96なので、一件も返却されない場合がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結果から考察してみる\n",
    "この結果を用いてどう考えるか？というところです。  \n",
    "現在はjinko_tableは「kenmei」をパーティションにしています。\n",
    "\n",
    "パーティションは多すぎてもいけませんし、少なすぎてもいけません。  \n",
    "この場合「cardinaryty_jinko_male」などでパーティションを切ってしまうとパーティションが多くなってしまいますし、一方で「cardinaryty_gengo」でパーティションを切るとデータが一つのパーティションに入り込んでしまいます。\n",
    "\n",
    "そのように考えると「cardinaryty_kenmei」は多くもなく少なくもないちょうどいいカーディナリティであることがわかります。\n",
    "\n",
    "セレクティビティに関してはcodeでは唯一に絞ることはできず、しかもデータが取れない場合があることがわかりました。\n",
    "特にプライマリーキー(ビッグデータ基盤ではUUIDを付与したりすることが多い)などをセレクティビティチェックした時にレコードが複数返却される(されない)場合はどこかの経路で何か間違えているということになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySparkでデータプロファイリングをしてみようその3\n",
    "データプロファイリング３では、コンシステンシーについて考えてみたいと思います。\n",
    "コンシステンシーとは一貫性があるかないかという指標です。\n",
    "\n",
    "例えばjinko_code(今回はマスターテーブルと考えてください)と今回のjinko_tableを使ってみていきましょう(作成はチャプター３で実施済みです)\n",
    "\n",
    "もっとも一般的な一貫性のチェックはマスターテーブルなどのコードとの一致率を調べることです。\n",
    "数値で出すというより、Yes Noくらいの判定でもOKです。\n",
    "\n",
    "マスターコードが更新されていない（もしくは正しく反映されていない）場合必ず結合時に紐つかないレコードが存在します。  \n",
    "データ分析においてはテーブルの結合はデータの価値を高めていく行為の一つです。  \n",
    "そこでデータの欠落が起きてしまうとそれだけで価値が下がってしまうことにもつながります。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "50\n",
      "False\n",
      "+----+\n",
      "|diff|\n",
      "+----+\n",
      "|  00|\n",
      "|  14|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 一貫しているかどうかを判定するためには集合演算を使います\n",
    "\n",
    "#jinko_codeにおけるcodeとjinko_tableにおけるcodeを比較してみることにします。\n",
    "#マスターテーブルですので、本来であれば差分は0となるはずです\n",
    "\n",
    "jinko_code=spark.sql(\"select distinct(code) from data_management_crush_course.jinko_code\")\n",
    "jinko_table=spark.sql(\"select distinct(code) from data_management_crush_course.jinko_table\")\n",
    "\n",
    "print(jinko_code.count())\n",
    "print(jinko_table.count())\n",
    "\n",
    "consistency_judge_f=True\n",
    "\n",
    "# 件数が多い方を左側にするといいです。\n",
    "# Aの集合からBの集合を引き算して残った個数をカウントしています\n",
    "if jinko_table.subtract(jinko_code).selectExpr('code as diff').count() !=0:\n",
    "    consistency_judge_f = False\n",
    "\n",
    "#結果\n",
    "print(consistency_judge_f)\n",
    "\n",
    "#　差分を表示してみる\n",
    "jinko_table.subtract(jinko_code).selectExpr('code as diff').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結果を格納しよう\n",
    "これまでの結果を格納してみましょう\n",
    "\n",
    "- 件数\n",
    "- セレクティビティ\n",
    "- コンシステンシーチェック\n",
    "\n",
    "これら３つの結果を保存してみましょう。\n",
    "\n",
    "それぞれ対応する変数は以下になります。\n",
    "\n",
    "- record_count\n",
    "- list_selectivity\n",
    "- consistency_judge_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+--------------------------------------+----------+-----------+----------------+----------------+\n",
      "|       database_name| table_name|    table_definition|                               sammary|record_num|selectivity|consistency_flag|frequency_access|\n",
      "+--------------------+-----------+--------------------+--------------------------------------+----------+-----------+----------------+----------------+\n",
      "|data_management_c...|jinko_table|CREATE TABLE `dat...|一旦テーブルの説明は空にしておきます。|       300|       0.96|           false|            null|\n",
      "+--------------------+-----------+--------------------+--------------------------------------+----------+-----------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import when\n",
    "metadata_df=spark.sql(\"select * from metadata_tmp.sample_metadata \")\n",
    "\n",
    "# メタデータ取得対象のデータを更新する\n",
    "metadata_df = metadata_df. \\\n",
    "    withColumn(\"record_num\", when(metadata_df.record_num.isNull() ,record_count). \\\n",
    "        otherwise(metadata_df.record_num))\n",
    "metadata_df = metadata_df. \\\n",
    "    withColumn(\"selectivity\", when(metadata_df.selectivity.isNull() ,list_selectivity). \\\n",
    "        otherwise(metadata_df.selectivity))\n",
    "metadata_df = metadata_df. \\\n",
    "    withColumn(\"consistency_flag\", when(metadata_df.consistency_flag.isNull() ,consistency_judge_f). \\\n",
    "        otherwise(metadata_df.consistency_flag))\n",
    "\n",
    "metadata_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#取得したデータをmetadata_tmp.sample_metadataに格納していきます\n",
    "#読み込んだテーブルに対して直接データを入れることができないので、一度ファイルを吐き出します\n",
    "\n",
    "spark.sql(\"REFRESH TABLE metadata_tmp.sample_metadata\")\n",
    "metadata_df.write.mode('overwrite'). \\\n",
    "    parquet(\"/Users/saitouyuuki/Desktop/src/pyspark_datamanagement_metadata/dataset/tmp/\")\n",
    "insert_df=spark.read. \\\n",
    "    parquet(\"/Users/saitouyuuki/Desktop/src/pyspark_datamanagement_metadata/dataset/tmp/\")\n",
    "\n",
    "#取得したデータをmetadata_tmp.sample_metadataに格納していきます\n",
    "insert_df.createOrReplaceTempView(\"sample\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "Insert overwrite  table metadata_tmp.sample_metadata \n",
    "select  * from sample\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+--------------------------------------+----------+-----------+----------------+----------------+\n",
      "|       database_name| table_name|    table_definition|                               sammary|record_num|selectivity|consistency_flag|frequency_access|\n",
      "+--------------------+-----------+--------------------+--------------------------------------+----------+-----------+----------------+----------------+\n",
      "|data_management_c...|jinko_table|CREATE TABLE `dat...|一旦テーブルの説明は空にしておきます。|       300|       0.96|           false|            null|\n",
      "+--------------------+-----------+--------------------+--------------------------------------+----------+-----------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 結果の確認をしてみます\n",
    "\n",
    "spark.sql(\"select * from metadata_tmp.sample_metadata \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thu Nov 25 16:42:40 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 16:42:41 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 17:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 17:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 17:42:41 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 17:42:41 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 18:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 18:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 18:42:41 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 18:42:41 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 19:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 19:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 19:42:41 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 19:42:41 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 20:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 20:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 20:42:41 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 20:42:41 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 21:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 21:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 21:42:41 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 21:42:41 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 22:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "Thu Nov 25 22:18:05 JST 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n"
     ]
    }
   ],
   "source": [
    "# Stopは忘れずに\n",
    "# 忘れてしまうと、いつの間にか接続が溜まっていってしまいます\n",
    "spark.stop()\n",
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ品質管理\n",
    "ここで一つ別のトピックについて言及しようと思います。\n",
    "それがデータ品質管理です。\n",
    "\n",
    "データ品質管理とは、データプロファリングの延長線にあるものですが、データがより良い状態を達成するための方法の一つです。  \n",
    "データは当然ながら「正しい」状態で配置されていることが好ましいのは当たり前ですが、闇雲に施策を打ってもうまくいきません。\n",
    "\n",
    "そこでデータプロファイリングを使いながらデータの不備を発見しその不備に対してアクションを取っていくことが必要です。\n",
    "\n",
    "アクションとは\n",
    "\n",
    "- 対向システム(ここでのシステムは、データソース側のシステムのこと)自体の修正\n",
    "- データ自体の修正（再集計など）\n",
    "\n",
    "が挙げられます。\n",
    "入門のコースのためデータ品質管理は取り上げませんが、  \n",
    "今回のデータプロファイリングの延長戦にはデータ品質管理が存在していると認識してもらえるだけでもまずは良いと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習答え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定のフォーマットに沿っているもの\n",
    "df=spark.sql(\"select * from data_management_crush_course.jinko_table \")\n",
    "expr = \"[0-9]{2}\"\n",
    "dx = df.filter(df[\"code\"].rlike(expr))\n",
    "dx.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定のフォーマットに沿っていないもの\n",
    "df=spark.sql(\"select * from data_management_crush_course.jinko_table \")\n",
    "expr = \"[0-9]{2}\"\n",
    "dx = df.filter(df[\"code\"].rlike(expr))\n",
    "# 全体から指定フォーマットに沿っているものを除いています。\n",
    "df.subtract(dx).count()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cadefa720d1a2267f4d12d08d812560a64cfe891877bc388bf0e8af3e4846067"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
